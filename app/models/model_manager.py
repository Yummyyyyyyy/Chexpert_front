"""
æ¨¡å‹ç®¡ç†å™¨
è´Ÿè´£åŠ è½½ã€ç®¡ç†å’Œç¼“å­˜æ·±åº¦å­¦ä¹ æ¨¡å‹
"""
from loguru import logger
from typing import Optional
import os

from app.config import settings


class ModelManager:
    """
    æ¨¡å‹ç®¡ç†å™¨ç±»
    ç”¨äºåŠ è½½å’Œç®¡ç†æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆLLaVAã€åˆ†ç±»æ¨¡å‹ç­‰ï¼‰

    ã€TODO - åç«¯å›¢é˜Ÿæˆå‘˜éœ€è¦å®ç°ã€‘:
    1. å®ç°æ¨¡å‹åŠ è½½é€»è¾‘ï¼ˆload_classification_model, load_llava_modelï¼‰
    2. æ ¹æ®å®é™…ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆPyTorch/TensorFlowï¼‰è°ƒæ•´ä»£ç 
    3. å®ç°æ¨¡å‹é¢„çƒ­ï¼ˆwarmupï¼‰æé«˜é¦–æ¬¡æ¨ç†é€Ÿåº¦
    4. è€ƒè™‘æ·»åŠ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
    5. æ·»åŠ GPU/CPUè‡ªåŠ¨åˆ‡æ¢é€»è¾‘
    """

    def __init__(self):
        self.classification_model = None  # ç–¾ç—…åˆ†ç±»æ¨¡å‹
        self.llava_model = None  # LLaVAå¤šæ¨¡æ€æ¨¡å‹
        self.device = settings.DEVICE  # cuda/cpu/mps

    async def load_classification_model(self):
        """
        åŠ è½½ç–¾ç—…åˆ†ç±»æ¨¡å‹

        ã€TODOã€‘åç«¯å›¢é˜Ÿæˆå‘˜å®ç°:
        ```python
        import torch
        from your_model import CheXpertClassifier

        model_path = os.path.join(settings.MODEL_BASE_DIR, "classification_model.pth")
        self.classification_model = CheXpertClassifier()
        self.classification_model.load_state_dict(torch.load(model_path))
        self.classification_model.to(self.device)
        self.classification_model.eval()
        logger.success("âœ… åˆ†ç±»æ¨¡å‹åŠ è½½æˆåŠŸ")
        ```
        """
        logger.warning("âš ï¸  åˆ†ç±»æ¨¡å‹åŠ è½½é€»è¾‘å¾…å®ç° (model_manager.py:43)")
        # æ¨¡æ‹ŸåŠ è½½
        self.classification_model = "classification_model_placeholder"

    async def load_llava_model(self):
        """
        åŠ è½½LLaVAå¤šæ¨¡æ€æ¨¡å‹

        ã€TODOã€‘åç«¯å›¢é˜Ÿæˆå‘˜å®ç°:
        ```python
        from transformers import LlavaForConditionalGeneration, AutoProcessor

        if settings.LLAVA_MODEL_PATH:
            self.llava_model = LlavaForConditionalGeneration.from_pretrained(
                settings.LLAVA_MODEL_PATH,
                device_map=self.device
            )
            self.processor = AutoProcessor.from_pretrained(settings.LLAVA_MODEL_PATH)
            logger.success("âœ… LLaVAæ¨¡å‹åŠ è½½æˆåŠŸ")
        else:
            logger.warning("âš ï¸  æœªé…ç½®LLAVA_MODEL_PATH")
        ```
        """
        logger.warning("âš ï¸  LLaVAæ¨¡å‹åŠ è½½é€»è¾‘å¾…å®ç° (model_manager.py:65)")
        # æ¨¡æ‹ŸåŠ è½½
        self.llava_model = "llava_model_placeholder"

    async def load_all_models(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸ“¦ å¼€å§‹åŠ è½½æ‰€æœ‰æ¨¡å‹...")
        await self.load_classification_model()
        await self.load_llava_model()
        logger.success("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆ")

    def get_classification_model(self):
        """è·å–åˆ†ç±»æ¨¡å‹å®ä¾‹"""
        if self.classification_model is None:
            raise RuntimeError("åˆ†ç±»æ¨¡å‹å°šæœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_classification_model()")
        return self.classification_model

    def get_llava_model(self):
        """è·å–LLaVAæ¨¡å‹å®ä¾‹"""
        if self.llava_model is None:
            raise RuntimeError("LLaVAæ¨¡å‹å°šæœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_llava_model()")
        return self.llava_model


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
model_manager = ModelManager()
